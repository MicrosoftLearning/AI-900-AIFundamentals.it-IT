{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language Understanding\r\n",
        "\r\n",
        "Sempre più spesso, ci aspettiamo che i computer siano in grado di usare l'IA per capire i comandi vocali o digitati nel linguaggio naturale. Ad esempio, potresti voler implementare un sistema domotico per controllare i tuoi dispositivi domestici utilizzando comandi vocali come \"accendi la luce\" o \"accendi il ventilatore\" e avere un dispositivo basato su intelligenza artificiale che capisca il comando ed esegua l'azione appropriata.\r\n",
        "\r\n",
        "![Un robot in ascolto](./images/language_understanding.jpg)\r\n",
        "\r\n",
        "## Creare risorse di creazione e previsione\r\n",
        "\r\n",
        "I servizi cognitivi di Microsoft includono il servizio Language Understanding, che consente di definire le *finalità* applicate alle *entità* sulla base di *espressioni*. \r\n",
        "\r\n",
        "Per usare il servizio Language Understanding, occorrono due tipologie di risorse:\r\n",
        "\r\n",
        "- Una risorsa di *creazione*: usata per definire, sottoporre a training e testare il modello linguistico. Deve essere una risorsa **Language Understanding - Creazione** nella tua sottoscrizione di Azure.\r\n",
        "- Una risorsa di *previsione*: usata per pubblicare modelli e gestire richieste dalle applicazioni client che la usano. Questa può essere una risorsa **Language Understanding** o **Servizi cognitivi** nella tua sottoscrizione di Azure.\r\n",
        "\r\n",
        "Puoi usare una risorsa **Language Understanding** o **Servizi cognitivi** per *pubblicare* un'app Language Understanding, ma devi creare una risorsa **Language Understanding** separata per *creare* l'app.\r\n",
        "\r\n",
        "> **Importante**: Le risorse di creazione devono essere create in una delle tre *aree geografiche* (Europa, Australia o Stati Uniti). I modelli creati nelle risorse di creazione europee o australiane possono essere distribuiti solo su risorse di previsione in Europa o Australia, rispettivamente; i modelli creati nelle risorse di creazione statunitensi possono essere distribuiti su risorse di previsione in qualsiasi località di Azure diversa da Europa e Australia. Consulta la [documentazione sulle aree geografiche di creazione e pubblicazione](https://docs.microsoft.com/azure/cognitive-services/luis/luis-reference-regions) per i dettagli su come abbinare le località di creazione e previsione.\r\n",
        "\r\n",
        "1. In un'altra scheda del browser, apri il portale di Azure all'indirizzo [https://portal.azure.com](https://portal.azure.com), accedendo con il tuo account Microsoft.\r\n",
        "2. Fai clic su **+ Crea una risorsa** e cerca *Language Understanding*.\r\n",
        "3. Nell'elenco dei servizi, fai clic su **Language Understanding**.\r\n",
        "4. Nel pannello di **Language Understanding**, fai clic su **Crea**.\r\n",
        "5. Nel pannello **Crea**, inserisci i dettagli seguenti e fai clic su **Crea**\r\n",
        "   - **Opzione Crea**: Entrambi\r\n",
        "   - **Nome**: *Un nome univoco per il tuo servizio*\r\n",
        "   - **Sottoscrizione**: *Seleziona la tua sottoscrizione di Azure*\r\n",
        "   - **Gruppo di risorse**: *Seleziona un gruppo di risorse esistenti o creane uno nuovo*\r\n",
        "   - **Posizione di creazione**: *Seleziona la tua posizione preferita*\r\n",
        "   - **Piano tariffario di creazione**: F0\r\n",
        "   - **Località previsione**: *Scegli una posizione nella stessa area geografica della posizione di creazione*\r\n",
        "   - **Piano tariffario previsione**: F0\r\n",
        "   \r\n",
        "6. Attendi la creazione delle risorse e ricorda che viene effettuato il provisioning di due risorse di Language Understanding, una per la creazione e un'altra per la previsione. Puoi visualizzarle accedendo al gruppo di risorse in cui le hai create.\r\n",
        "\r\n",
        "### Creare un'app Language Understanding\r\n",
        "\r\n",
        "Per implementare la comprensione del linguaggio naturale con Language Understanding, puoi creare un'app e aggiungere entità, finalità ed espressioni per definire quali comandi dovranno essere compresi dall'app:\r\n",
        "\r\n",
        "1. In una nuova scheda del browser, apri il portale di Language Understanding per l'area geografica di creazione in cui hai creato la tua risorsa di creazione:\r\n",
        "    - Stati Uniti: [https://www.luis.ai](https://www.luis.ai)\r\n",
        "    - Europa: [https://eu.luis.ai](https://eu.luis.ai)\r\n",
        "    - Australia: [https://au.luis.ai](https://au.luis.ai)\r\n",
        "\r\n",
        "2. Accedi utilizzando l'account Microsoft associato alla tua sottoscrizione di Azure. Se è la prima volta che accedi al portale di Language Understanding potresti dover concedere all'app alcuni permessi in modo che possa accedere ai dettagli del tuo account. Quindi, completa i passaggi di *benvenuto* selezionando la risorsa di creazione di Language Understanding esistente appena creata nella tua sottoscrizione di Azure. \r\n",
        "\r\n",
        "3. Apri la pagina **App di conversazione** e seleziona la tua sottoscrizione e la risorsa di creazione di Language Understanding. Quindi crea una nuova app per conversazioni con le impostazioni seguenti:\r\n",
        "   - **Nome**: Home Automation\r\n",
        "   - **Cultura**: italiano (*se questa opzione non è disponibile lascia il campo vuoto*)\r\n",
        "   - **Descrizione**: Domotica semplice\r\n",
        "   - **Risorsa di previsione**: *La tua risorsa di previsione di Language Understanding*\r\n",
        "\r\n",
        "4. Se compare un riquadro con dei consigli per creare un'app di Language Understanding efficace, chiudila.\r\n",
        "\r\n",
        "### Creare un'entità\r\n",
        "\r\n",
        "Un'*entità* è qualcosa che il tuo modello linguistico può identificare e usare per compiere delle azioni. In questo caso, la tua app di Language Understanding può essere usata per controllare vari *dispositivi* in ufficio, come luci o ventilatori; quindi puoi creare un'entità *dispositivo* che includa un elenco dei tipi di dispositivo con cui vuoi che l'app funzioni. Per ciascun tipo di dispositivo puoi creare un sottoelenco che identifichi il nome del dispositivo (ad esempio *luce*) e qualsiasi sinonimo che può essere usato per riferirsi a questo tipo di dispositivo (ad esempio *lampada*).\r\n",
        "\r\n",
        "1. Nella pagina di Language Understanding per la tua app, nel riquadro a sinistra, fai clic su **Entità**. Quindi fai clic su **Crea** e crea una nuova identità chiamata **dispositivo**, seleziona il tipo **Elenco**, quindi fai clic su **Crea**.\r\n",
        "2. Nella pagina **Elementi elenco**, in **Valori normalizzati** digita **luce**, quindi premi INVIO.\r\n",
        "3. Una volta aggiunto il valore **luce**, in **Sinonimi** digita **lampada** e premi INVIO.\r\n",
        "4. Aggiungi un secondo elemento dell'elenco chiamato **ventilatore** con il sinonimo **aria condizionata**.\r\n",
        "\r\n",
        "> **Nota**: Per questa esercitazione, usa il testo esatto in minuscolo o maiuscolo come indicato _(esempio: luce **non** Luce)_ e non aggiungere spazi. \r\n",
        "\r\n",
        "### Creare le finalità\r\n",
        "\r\n",
        "Una *finalità* è un'azione che vuoi eseguire su una o più entità: ad esempio, potresti voler accendere una luce o spegnere un ventilatore. In questo caso, puoi definire due finalità: una per accendere un dispositivo e un'altra per spegnere un dispositivo. Per ciascuna finalità specificherai *espressioni* campione che indicano una tipologia di linguaggio usata per indicare la finalità.\r\n",
        "\r\n",
        "> **Nota**: Per questo lab, utilizza esattamente le lettere maiuscole e minuscole come da istruzioni _(esempio: \"accendi la luce\" **non** \"Accendi la luce .\")_ e non inserire spazi aggiuntivi. \r\n",
        "\r\n",
        "1. Nel riquadro sinistro, fai clic su **Finalità**. Quindi fai clic su **Crea** e aggiungi una finalità con il nome **accendi** e fai clic su **Fatto**.\r\n",
        "2. Sotto al titolo **Esempi** e al sottotitolo **Input dell'utente di esempio**, digita l'espressione ***accendi la luce*** e premi **Invio** per aggiungere l'espressione all'elenco.\r\n",
        "3. Nell'espressione *accendi la luce*, fai clic sulla parola \"luce\" e assegnala al valore **luce** dell'entità **dispositivo**\r\n",
        "\r\n",
        "![Come assegnare la parola \"luce\" al valore dell'entità.](./images/assign_entity.jpg)\r\n",
        "\r\n",
        "4. Aggiungi una seconda espressione alla finalità **accendi** con la frase ***accendi il ventilatore***. Quindi assegna la parola \"ventilatore\" al valore **ventilatore** dell'entità **dispositivo**.\r\n",
        "5. Nel riquadro sinistro, fai clic su **Finalità** e poi su **Crea** per aggiungere una seconda finalità con il nome **spegni**.\r\n",
        "6. Nella pagina **Espressioni** per la finalità **spegni**, aggiungi l'espressione ***spegni la luce*** e assegna la parola \"luce\" al valore **luce** dell'entità **dispositivo**.\r\n",
        "7. Aggiungi una seconda espressione alla finalità **spegni** con la frase ***spegni il ventilatore***. Quindi collega la parola \"ventilatore\" al valore **ventilatore** dell'entità **dispositivo**.\r\n",
        "\r\n",
        "### Eseguire il training e testare il modello linguistico\r\n",
        "\r\n",
        "Ora è il momento di usare i dati che hai fornito sotto forma di entità, intenti ed espressioni per eseguire il training del modello linguistico della tua app.\r\n",
        "\r\n",
        "1. Sulla parte superiore della pagina Language Understanding per la tua app, fai clic su **Esegui il training** per eseguire il training il modello linguistico\r\n",
        "2. Una volta preparato il modello, fai clic su **Test** e usa il riquadro di test per visualizzare la finalità prevista per le seguenti frasi:\r\n",
        "    * *accendi la luce*\r\n",
        "    * *spegni il ventilatore*\r\n",
        "    * *spegni la lampada*\r\n",
        "    * *accendi l'aria condizionata*\r\n",
        "3. Chiudi il riquadro di test.\r\n",
        "    \r\n",
        "### Pubblicare il modello e configurare gli endpoint\r\n",
        "\r\n",
        "Per usare il modello preparato in un'applicazione client, occorre pubblicarlo come un endpoint a cui l'applicazione client può inviare nuove espressioni, da cui verranno previste nuove finalità ed entità.\r\n",
        "\r\n",
        "1. Sulla parte superiore della pagina Language Understanding per la tua app, fai clic su **Pubblica**. Quindi seleziona **Slot di produzione** e fai clic su **Fatto**.\r\n",
        "\r\n",
        "2. Dopo aver pubblicato il modello, nella parte superiore della pagina Language Understanding per la tua app fai clic su **Gestisci**. Quindi annota l'**ID app** della tua app nella scheda **Impostazioni**. Copialo e incollalo nel codice seguente per sostituire **YOUR_LU_APP_ID**.\r\n",
        "\r\n",
        "3. Sulla scheda **Risorse di Azure**, annota la **Chiave primaria** e l'**URL endpoint** per la tua risorsa di previsione. Coppia e incolla questi valori nel codice seguente, sostituendo **YOUR_LU_KEY** e **YOUR_LU_ENDPOINT**.\r\n",
        "\r\n",
        "4. Esegui la cella seguente facendo click sul rispettivo pulsante **Esegui cella** (&#9655;) (a sinistra della cella) e, quando richiesto, inserisci il testo *accendi la luce*. Il testo viene interpretato dal tuo modello di Language Understanding e viene visualizzata un'immagine adeguata.\r\n",
        "\r\n",
        "### **(!) Importante**: \r\n",
        "Cerca la richiesta nella parte superiore della finestra: Dovrai digitare *accendi la luce* e premere **invio**. \r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from python_code import luis\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "    # Set up API configuration\n",
        "    luis_app_id = 'YOUR_LU_APP_ID'\n",
        "    luis_key = 'YOUR_LU_KEY'\n",
        "    luis_endpoint = 'YOUR_LU_ENDPOINT'\n",
        "\n",
        "    # prompt for a command\n",
        "    command = input('Please enter a command: \\n')\n",
        "\n",
        "    # get the predicted intent and entity (code in python_code.home_auto.py)\n",
        "    action = luis.get_intent(luis_app_id, luis_key, luis_endpoint, command)\n",
        "\n",
        "    # display an appropriate image\n",
        "    img_name = action + '.jpg'\n",
        "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
        "    plt.axis('off')\n",
        "    plt. imshow(img)\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696381331
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (!) Verifica \r\n",
        "Hai eseguito la cella precedente e digitato la frase *accendi la luce* quando è comparsa la richiesta? La richiesta apparirà nella parte superiore della finestra.  \r\n",
        "\r\n",
        "Esegui di nuovo la cella precedente tentando le frasi seguenti:\r\n",
        "\r\n",
        "* *accendi la luce*\r\n",
        "* *disattiva la lampada*\r\n",
        "* *accendi il ventilatore*\r\n",
        "* *accendi la luce*\r\n",
        "* *spegni la luce*\r\n",
        "* *spegni il ventilatore*\r\n",
        "* *accendi l'aria condizionata*\r\n",
        "\r\n",
        "Se hai eseguito la cella precedente ed è comparso un punto interrogativo, potresti aver usato un testo o una spaziatura leggermente diversi da quelli indicati al momento della creazione di un'entità, finalità o espressione.\r\n",
        "\r\n",
        "> **Nota**: per saperne di più sui codici usati per recuperare le finalità e le entità dalla tua app di Language Understanding, consulta il file **luis.py** nella cartella **python_code**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggiungere il controllo vocale\r\n",
        "\r\n",
        "Finora abbiamo visto come analizzare un testo, ma sempre più sistemi di IA consentono agli umani di comunicare con servizi software grazie al riconoscimento vocale. Per supportare questa funzionalità, il servizio cognitivo **Voce** offre un modo semplice per trascrivere la lingua parlata in testo.\r\n",
        "\r\n",
        "### Crea una risorsa di Servizi Cognitivi\r\n",
        "\r\n",
        "Se non ne hai già una, procedi come segue per creare una risorsa di **Servizi Cognitivi** nella tua sottoscrizione di Azure:\r\n",
        "\r\n",
        "> **Nota**: se hai già una risorsa Servizi cognitivi, basta aprire la rispettiva pagina **Avvio rapido** nel portale di Azure e copiarne la chiave e la posizione nella cella sottostante. Altrimenti, procedi come segue per crearne una.\r\n",
        "\r\n",
        "1. In un'altra scheda del browser, apri il portale di Azure all'indirizzo [https://portal.azure.com](https://portal.azure.com), accedendo con il tuo account Microsoft.\r\n",
        "2. Fai clic sul pulsante **&#65291;Crea una risorsa**, cerca *Servizi cognitivi* e crea una risorsa di **Servizi cognitivi** con le impostazioni seguenti:\r\n",
        "    - **Sottoscrizione**: *La tua sottoscrizione di Azure*.\r\n",
        "    - **Gruppo di risorse**: *Seleziona o crea un gruppo di risorse con un nome univoco*.\r\n",
        "    - **Area geografica**: *Scegli una qualsiasi area disponibile*:\r\n",
        "    - **Nome**: *Immetti un nome univoco*.\r\n",
        "    - **Piano tariffario**: S0\r\n",
        "    - **Spuntando questa casella, certifico che l'utilizzo di questo servizio non è da parte o per conto di un dipartimento di polizia degli Stati Uniti**: Selezionato.\r\n",
        "    - **Confermo di aver letto e compreso gli avvisi**: Selezionato.\r\n",
        "3. Attendi il completamento della distribuzione. Quindi accedi alla risorsa Servizi cognitivi e sulla pagina **Avvio rapido** annota le chiavi e la posizione. Ne avrai bisogno per connetterti alle tue risorse Servizi cognitivi dalle applicazioni client.\r\n",
        "\r\n",
        "### Ottenere la chiave e la posizione della risorsa Servizi cognitivi\r\n",
        "\r\n",
        "Per usare la risorsa di servizi cognitivi, le applicazioni client hanno bisogno della chiave di autenticazione e della posizione:\r\n",
        "\r\n",
        "1. Nel portale di Azure, nella pagina **Chiavi ed endpoint** per la tua risorsa di servizio cognitivo, copia la **Key1** per la tua risorsa e incollala nel codice sottostante, sostituendo **YOUR_COG_KEY**.\r\n",
        "2. Copia la **Posizione** della tua risorsa e incollala nel codice seguente sostituendo **TUA_POSIZIONE_COG**.\r\n",
        ">**Nota**: Rimani nella pagina **Chiavi ed endpoint** e copia la **Posizione** da questa pagina (esempio: _westus_). Non aggiungere spazi tra le parole per il campo Posizione. \r\n",
        "3. Esegui il codice nella cella seguente. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696409914
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora esegui la cella seguente per trascrivere il parlato da un file audio e usala come comando per la tua app di Language Understanding."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from python_code import luis\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "from playsound import playsound\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "try:   \n",
        "\n",
        "    # Get spoken command from audio file\n",
        "    file_name = 'light-on.wav'\n",
        "    audio_file = os.path.join('data', 'luis', file_name)\n",
        "\n",
        "    # Configure speech recognizer\n",
        "    speech_config = SpeechConfig(cog_key, cog_location)\n",
        "    audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "    speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "    # Use a one-time, synchronous call to transcribe the speech\n",
        "    speech = speech_recognizer.recognize_once()\n",
        "\n",
        "    # Get the predicted intent and entity (code in python_code.home_auto.py)\n",
        "    action = luis.get_intent(luis_app_id, luis_key, luis_endpoint, speech.text)\n",
        "\n",
        "    # Get the appropriate image\n",
        "    img_name = action + '.jpg'\n",
        "\n",
        "    # Display image \n",
        "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
        "    plt.axis('off')\n",
        "    plt. imshow(img)\n",
        "    playsound(audio_file)\n",
        "\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696420498
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prova a modificare la cella precedente per usare il file audio **light-off.wav**.\r\n",
        "\r\n",
        "## Scopri di più\r\n",
        "\r\n",
        "Per ulteriori informazioni su Language Understanding consulta la [documentazione del servizio](https://docs.microsoft.com/azure/cognitive-services/luis/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}