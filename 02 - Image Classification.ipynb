{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classificazione immagini\r\n",
        "\r\n",
        "Il servizio cognitivo *Visione artificiale* fornisce utili modelli pre-sviluppati per lavorare con le immagini, ma spesso avrai bisogno di eseguire il training del tuo modello per la visione artificiale. Ad esempio, supponiamo che la società di vendita al dettaglio Northwind Traders voglia creare un sistema di cassa automatica che identifichi gli articoli di spesa che i clienti vogliono comprare in base a un'immagine scattata da una telecamera alla cassa. Per farlo, è necessario eseguire il training di un modello di classificazione che possa classificare le immagini per identificare l'articolo da acquistare.\r\n",
        "\r\n",
        "![Un robot con un blocco per appunti che classifica le immagini di una mela, una banana e un'arancia](./images/image-classification.jpg)\r\n",
        "\r\n",
        "In Azure, è possibile utilizzare il servizio cognitivo ***Visione personalizzata*** per eseguire il training di un modello di classificazione delle immagini basato su immagini esistenti. Gli elementi per creare una soluzione di classificazione delle immagini sono due. Innanzitutto, devi eseguire il training di un modello per riconoscere le diverse classi utilizzando le immagini esistenti. Quindi, quando il modello è stato sottoposto a training è necessario pubblicarlo come un servizio che può essere consumato dalle applicazioni.\r\n",
        "\r\n",
        "## Crea una risorsa Visione personalizzata\r\n",
        "\r\n",
        "Per utilizzare il servizio Visione personalizzata, hai bisogno di una risorsa di Azure che puoi utilizzare per *eseguire il training* di un modello e una risorsa con la quale puoi *pubblicarlo* per usare le applicazioni. La risorsa per una (o entrambe) le attività può essere una risorsa generale di **Servizi cognitivi**, o una risorsa specifica di **Visione personalizzata**. Puoi usare la stessa risorsa di Servizi cognitivi per ognuna di queste attività, oppure puoi usare risorse diverse (nella stessa area geografica) per ogni attività per gestire i costi separatamente.\r\n",
        "\r\n",
        "Usa le istruzioni seguenti per creare una nuova risorsa **Visione personalizzata**.\r\n",
        "\r\n",
        "1. In una nuova scheda del browser, apri il portale Azure all'indirizzo [https://portal.azure.com](https://portal.azure.com) e accedi utilizzando l'account Microsoft associato alla tua sottoscrizione di Azure.\r\n",
        "2. Seleziona il pulsante **&#65291;Crea una risorsa**, cerca *visione personalizzata* e crea una risorsa di **Visione personalizzata** con le impostazioni seguenti:\r\n",
        "    - **Crea opzioni**: Entrambe\r\n",
        "    - **Sottoscrizione**: *la tua sottoscrizione di Azure*\r\n",
        "    - **Gruppo di risorse**: *Seleziona o crea un gruppo di risorse con un nome univoco*\r\n",
        "    - **Nome**: *Immetti un nome univoco*\r\n",
        "    - **Località training**: *Scegli una qualsiasi area disponibile*\r\n",
        "    - **Piano tariffario training**: F0\r\n",
        "    - **Località previsione**: *La stessa area geografica della risorsa di training*\r\n",
        "    - **Piano tariffario previsione**: F0\r\n",
        "\r\n",
        "    > **Nota**: Se disponi già di un servizio di visione personalizzata F0 nella tua sottoscrizione, seleziona **S0**.\r\n",
        "\r\n",
        "3. Attendi che le risorse vengano create e tieni presente che vengono fornite due risorse di Visione personalizzata: una per il training e un'altra per la previsione. Puoi visualizzarle accedendo al gruppo di risorse in cui le hai create.\r\n",
        "\r\n",
        "## Crea un progetto Visione personalizzata\r\n",
        "\r\n",
        "Per eseguire il training di un modello di rilevamento degli oggetti, è necessario creare un progetto Visione personalizzata basato sulla risorsa di training. Per farlo, userai il portale Visione personalizzata.\r\n",
        "\r\n",
        "1. Scaricare ed estrarre le immagini di training da https://aka.ms/fruit-images. **Nota:** come soluzione temporanea, nel caso non sia possibile accedere alle immagini di training, passare a https://www.github.com e quindi a https://aka.ms/fruit-images.  \r\n",
        "2. In un'altra scheda del browser, apri il portale Visione personalizzata all'indirizzo [https://customvision.ai](https://customvision.ai). Se richiesto, accedi utilizzando l'account Microsoft associato alla tua sottoscrizione di Azure e accetta i termini del servizio.\r\n",
        "3. Nel portale Visione personalizzata, crea un nuovo progetto con le impostazioni seguenti:\r\n",
        "    - **Nome**: Grocery Checkout\r\n",
        "    - **Descrizione**: Classificazione delle immagini per alimentari\r\n",
        "    - **Risorsa**: *La risorsa Visione personalizzata creata in precedenza*\r\n",
        "    - **Tipi progetto**: Classificazione\r\n",
        "    - **Tipi classificazione**: Multiclasse (singolo tag per immagine)\r\n",
        "    - **Domini**: Cibo\r\n",
        "4. Fai clic su **\\[+\\] Aggiungi immagini** e seleziona tutti i file nella cartella **mela** che hai estratto in precedenza. Carica quindi i file di immagine, specificando il tag *mela*, come di seguito:\r\n",
        "\r\n",
        "![Carica la mela con il tag mela](./images/upload_apples.jpg)\r\n",
        "   \r\n",
        "5. Ripeti il passaggio precedente per caricare le immagini nella cartella **banana** con il tag *banana*, e le immagini nella cartella **arancia** con il tag *arancia*.\r\n",
        "6. Esplora le immagini che hai caricato nel progetto Visione personalizzata: dovrebbero essere presenti 15 immagini di ogni classe, come di seguito:\r\n",
        "\r\n",
        "![Immagini con tag di frutta: 15 mele, 15 banane e 15 arance](./images/fruit.jpg)\r\n",
        "    \r\n",
        "7. Nel progetto Visione personalizzata, sopra le immagini, fai clic su **Esegui il training** per eseguire il training di un modello di classificazione utilizzando le immagini con tag. Seleziona l'opzione **Training rapido**, e poi attendi che l'iterazione del training sia completata (potrebbe essere necessario un minuto circa).\r\n",
        "8. Quando è stato eseguito il training dell'iterazione del modello, esamina le metriche di prestazione *Precisione*, *Richiamo* e *AP*, che misurano l'accuratezza della previsione del modello di classificazione e dovrebbero essere tutte elevate.\r\n",
        "\r\n",
        "## Testa il modello\r\n",
        "\r\n",
        "Prima di pubblicare questa iterazione del modello da usare per le applicazioni, dovresti testarlo.\r\n",
        "\r\n",
        "1. Sopra le metriche di prestazione, fai clic su **Test rapido**.\r\n",
        "2. Nella casella **URL dell'immagine**, digita `https://aka.ms/apple-image` e fai clic su &#10132;\r\n",
        "3. Visualizza le previsioni restituite dal tuo modello: il punteggio di probabilità per la *mela* dovrebbe essere il più alto, come di seguito:\r\n",
        "\r\n",
        "![Un'immagine con una previsione della classe di una mela](./images/test-apple.jpg)\r\n",
        "\r\n",
        "4. Chiudi la finestra **Test rapido**.\r\n",
        "\r\n",
        "## Pubblica e consuma il modello di classificazione delle immagini\r\n",
        "\r\n",
        "Ora è tutto pronto per pubblicare il tuo modello sottoposto a training e usarlo da un'applicazione client.\r\n",
        "\r\n",
        "9. Fai clic su **&#128504; Pubblica** per pubblicare il modello sottoposto a training con le impostazioni seguenti:\r\n",
        "    - **Nome modello**: groceries\r\n",
        "    - **Risorsa di previsione**: *La risorsa di previsione creata in precedenza*.\r\n",
        "\r\n",
        "### (!) Verifica \r\n",
        "Hai usato lo stesso nome del modello: **groceries**?   \r\n",
        "\r\n",
        "10. Dopo la pubblicazione, fai clic sull'icona delle *impostazioni * (&#9881;) in alto a destra della pagina **Prestazioni** per visualizzare le impostazioni del progetto. Quindi, in **Generali** (a sinistra), copia l'**ID progetto**. Scorri verso il basso e incollalo nella cella del codice sotto il passaggio 13 sostituendo **YOUR_PROJECT_ID**.\r\n",
        "\r\n",
        "![ID progetto nelle impostazioni del progetto](./images/cv_project_settings.jpg)\r\n",
        "\r\n",
        "> _**Nota**: Se hai usato una risorsa di **Servizi cognitivi** anziché creare una risorsa di **Visione personalizzata** all'inizio di questo esercizio, puoi copiare la sua chiave e l'endpoint dal lato destro delle impostazioni del progetto, incollarlo nella cella di codice di seguito, ed eseguirlo per vedere i risultati. Altrimenti, continua a completare i passaggi seguenti per ottenere la chiave e l'endpoint per la tua risorsa di previsione Visione personalizzata._\r\n",
        "\r\n",
        "11. In alto a sinistra della pagina **Impostazioni progetto**, fai clic sull'icona *Galleria progetti* (&#128065;) per tornare alla pagina iniziale del portale Visione personalizzata, dove adesso è elencato il tuo progetto.\r\n",
        "\r\n",
        "12. Nella pagina iniziale del portale Visione personalizzata, in alto a destra, fai clic sull'icona delle *impostazioni* (&#9881;) per visualizzare le impostazioni del tuo servizio Visione personalizzata. Quindi, in **Risorse**, espandi la tua risorsa di **previsione** (<u>non</u> la risorsa di training) e copia i suoi valori **Chiave** ed **Endpoint** nella cella di codice sotto il passaggio 13, sostituendo **YOUR_KEY** e **YOUR_ENDPOINT**.\r\n",
        "\r\n",
        "### (!) Verifica \r\n",
        "Se stai usando una risorsa **Visione personalizzata**, hai usato la risorsa di **previsione** (<u>non</u> la risorsa di training)?\r\n",
        "\r\n",
        "![Chiave ed endpoint della risorsa di previsione nelle impostazioni di visione personalizzata](./images/cv_settings.jpg)\r\n",
        "\r\n",
        "13. Esegui la cella di codice di seguito facendo clic sul pulsante **Esegui cella** (&#9655;) (a sinistra della cella) per impostare le variabili sui valori dell'ID del progetto, della chiave e dell'endpoint."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\r\n",
        "cv_key = 'YOUR_KEY'\r\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\r\n",
        "\r\n",
        "model_name = 'groceries' # this must match the model name you set when publishing your model iteration (it's case-sensitive)!\r\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599691949340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora puoi utilizzare la chiave e l'endpoint con un client di Visione personalizzata per connetterti al tuo modello di classificazione di visione personalizzata.\r\n",
        "\r\n",
        "Esegui la cella di codice seguente per classificare una selezione di immagini di test utilizzando il tuo modello pubblicato.\r\n",
        "\r\n",
        "> **Nota**: Non preoccuparti troppo dei dettagli del codice. Utilizza l'SDK Visione artificiale per Python per ottenere una previsione di classe per ogni immagine nella cartella /data/image-classification/test-fruit"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
        "from msrest.authentication import ApiKeyCredentials\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import os\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# Get the test images from the data/vision/test folder\r\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\r\n",
        "test_images = os.listdir(test_folder)\r\n",
        "\r\n",
        "# Create an instance of the prediction service\r\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\r\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\r\n",
        "\r\n",
        "# Create a figure to display the results\r\n",
        "fig = plt.figure(figsize=(16, 8))\r\n",
        "\r\n",
        "# Get the images and show the predicted classes for each one\r\n",
        "print('Classifying images in {} ...'.format(test_folder))\r\n",
        "for i in range(len(test_images)):\r\n",
        "    # Open the image, and use the custom vision model to classify it\r\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\r\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\r\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\r\n",
        "    prediction = classification.predictions[0].tag_name\r\n",
        "    # Display the image with its predicted class\r\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\r\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\r\n",
        "    a.axis('off')\r\n",
        "    imgplot = plt.imshow(img)\r\n",
        "    a.set_title(prediction)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599692327514
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auspicabilmente, il tuo modello di classificazione delle immagini ha identificato correttamente gli alimentari nelle immagini.\r\n",
        "\r\n",
        "## Scopri di più\r\n",
        "\r\n",
        "Il servizio Visione personalizzata offre più capacità di quelle che abbiamo esplorato in questo esercizio. Ad esempio, puoi anche usare il servizio Visione personalizzata per creare modelli di *rilevamento degli oggetti*; che non solo classificano gli oggetti nelle immagini, ma identificano anche i *riquadri delimitatori del testo* che mostrano la posizione dell'oggetto nell'immagine.\r\n",
        "\r\n",
        "Per saperne di più sul servizio cognitivo Visione personalizzata, consulta la [documentazione di Visione personalizzata](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}